<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-5FELLLFHCP"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-5FELLLFHCP',{anonymize_ip:!1})}</script><meta property="og:title" content="Getting Started"><meta property="og:description" content="Welcome to PyTorch-Ignite’s quick start guide that covers the
essentials of getting a project up and running while walking through
basic concepts of Ignite. In just a few lines of code, you can get your
model trained and validated. The complete code can be found at the end
of this guide."><meta property="og:type" content="article"><meta property="og:url" content="https://pytorch-ignite.ai/tutorials/getting-started/"><meta property="og:image" content="https://pytorch-ignite.ai/images/logos/ignite_logo_feature.png"><meta property="article:section" content="tutorials"><meta property="article:published_time" content="2021-07-27T00:00:00+00:00"><meta property="article:modified_time" content="2021-07-29T17:28:32+06:30"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pytorch-ignite.ai/images/logos/ignite_logo_feature.png"><meta name=twitter:title content="Getting Started"><meta name=twitter:description content="Welcome to PyTorch-Ignite’s quick start guide that covers the
essentials of getting a project up and running while walking through
basic concepts of Ignite. In just a few lines of code, you can get your
model trained and validated. The complete code can be found at the end
of this guide."><meta name=description content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently."><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Getting Started | PyTorch-Ignite</title><link rel=stylesheet type=text/css href=/css/style.min.125203f72a92a60311cb74c041a2ee40c9a6af792496be325e393ab46013c90b.css integrity="sha256-ElID9yqSpgMRy3TAQaLuQMmmr3kklr4yXjk6tGATyQs="><link rel=stylesheet type=text/css href=/css/icons.css><link rel=stylesheet href=/css/custom.min.6024e3fad9853c08d3544a80b38ec38fd361bbe7fd6208a2f7e780625ee6bffb.css><link rel=icon type=image/svg+xml href=/images/logos/ignite_logomark.svg><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=Oxygen:wght@300;400;700&display=swap" rel=stylesheet><link rel=stylesheet href=/css/tutorials.min.732e21559f983449b32d1c9ce1a03559c702feb4f87f19509fd5f6ca56a81891.css></head><body><nav class="navbar is-fresh is-transparent no-shadow" role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item href=/><img src=/images/logos/ignite_logomark.svg alt width=112 height=28></a>
<a class="navbar-item is-hidden-desktop is-hidden-tablet"><div id=menu-icon-wrapper class=menu-icon-wrapper style=visibility:visible><svg width="1e3" height="1e3"><path class="path1" d="M3e2 4e2H7e2c2e2.0 2e2 350-1e2 450A4e2 4e2.0 012e2 2e2L8e2 8e2"/><path class="path2" d="M3e2 5e2H7e2"/><path class="path3" d="M7e2 6e2H3e2c-2e2.0-2e2-4e2 1e2-450A4e2 380 0 112e2 8e2L8e2 2e2"/></svg><button id=menu-icon-trigger class=menu-icon-trigger></button></div></a><a role=button class=navbar-burger aria-label=menu aria-expanded=false data-target=navbar-menu><span aria-hidden=true></span><span aria-hidden=true></span><span aria-hidden=true></span></a></div><div id=navbar-menu class="navbar-menu is-static"><div class=navbar-start><a class="navbar-item is-hidden-mobile"><div id=menu-icon-wrapper class=menu-icon-wrapper style=visibility:visible><svg width="1e3" height="1e3"><path class="path1" d="M3e2 4e2H7e2c2e2.0 2e2 350-1e2 450A4e2 4e2.0 012e2 2e2L8e2 8e2"/><path class="path2" d="M3e2 5e2H7e2"/><path class="path3" d="M7e2 6e2H3e2c-2e2.0-2e2-4e2 1e2-450A4e2 380 0 112e2 8e2L8e2 2e2"/></svg><button id=menu-icon-trigger class=menu-icon-trigger></button></div></a></div><div class=navbar-end><div class="navbar-item has-dropdown is-hoverable"><a class=navbar-link>Docs</a><div class=navbar-dropdown><a href=/guide/ class=navbar-item>Guide</a>
<a href=/tutorials/ class=navbar-item>Tutorials</a></div></div><a href=https://github.com/pytorch/ignite class="navbar-item is-secondary">GitHub</a>
<a href=/posts/ class="navbar-item is-secondary">Blog</a>
<a href=/community class="navbar-item is-secondary">Community</a></div></div></div></nav><section class="section is-medium has-sidebar"><div class=downloads><a class=colab href=https://colab.research.google.com/github/pytorch-ignite/pytorch-ignite.ai/blob/gh-pages/examples/getting-started.ipynb target=_blank rel="noopener noreferrer"><img src=/images/logos/colab.svg alt="Google Colab Logo" width=30 height=30>
<span>Run in Google Colab</span></a>
<a class=notebook href=/examples/getting-started.ipynb target=_blank rel="noopener noreferrer" download=getting-started.ipynb><img src=/images/logos/download.svg alt="Download Logo" width=20 height=20>
<span>Download as Jupyter Notebook</span></a>
<a class=source href=https://github.com/pytorch-ignite/pytorch-ignite.ai/blob/gh-pages/examples/getting-started.ipynb target=_blank rel="noopener noreferrer"><img src=/images/logos/github.svg alt="GitHub Logo" width=20 height=20>
<span>View on GitHub</span></a></div><div class="container sidebar-on"><div class=columns><div class="column is-centered-tablet-portrait"><h1 class="title tutorial-title">Getting Started</h1><h5 class="subtitle is-muted is-5"></h5></div></div><div class=tags><span class=tag><a href=/tags/pytorch-ignite>PyTorch-Ignite</a></span></div><div class=content><p>Welcome to <strong>PyTorch-Ignite</strong>’s quick start guide that covers the
essentials of getting a project up and running while walking through
basic concepts of Ignite. In just a few lines of code, you can get your
model trained and validated. The complete code can be found at the end
of this guide.</p><h2 id=prerequisites>Prerequisites</h2><p>This tutorial assumes you are familiar with the:</p><ol><li>Basics of Python and deep learning</li><li>Structure of PyTorch code</li></ol><h2 id=installation>Installation</h2><ol><li>From <code>pip</code></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>pip install pytorch-ignite
</code></pre></td></tr></table></div></div><ol><li>From <code>conda</code></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-shell data-lang=shell>conda install ignite -c pytorch
</code></pre></td></tr></table></div></div><p>See <a href=https://pytorch-ignite.ai/docs/how-to-guides/installation>here</a> for other installation
options.</p><h2 id=code>Code</h2><p>Import the following:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>from</span> <span class=nn>torch</span> <span class=kn>import</span> <span class=n>nn</span>
<span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span>
<span class=kn>from</span> <span class=nn>torchvision.datasets</span> <span class=kn>import</span> <span class=n>MNIST</span>
<span class=kn>from</span> <span class=nn>torchvision.models</span> <span class=kn>import</span> <span class=n>resnet18</span>
<span class=kn>from</span> <span class=nn>torchvision.transforms</span> <span class=kn>import</span> <span class=n>Compose</span><span class=p>,</span> <span class=n>Normalize</span><span class=p>,</span> <span class=n>ToTensor</span>

<span class=kn>from</span> <span class=nn>ignite.engine</span> <span class=kn>import</span> <span class=n>Engine</span><span class=p>,</span> <span class=n>Events</span><span class=p>,</span> <span class=n>create_supervised_trainer</span><span class=p>,</span> <span class=n>create_supervised_evaluator</span>
<span class=kn>from</span> <span class=nn>ignite.metrics</span> <span class=kn>import</span> <span class=n>Accuracy</span><span class=p>,</span> <span class=n>Loss</span>
<span class=kn>from</span> <span class=nn>ignite.handlers</span> <span class=kn>import</span> <span class=n>ModelCheckpoint</span>
<span class=kn>from</span> <span class=nn>ignite.contrib.handlers</span> <span class=kn>import</span> <span class=n>TensorboardLogger</span><span class=p>,</span> <span class=n>global_step_from_engine</span>
</code></pre></td></tr></table></div></div><p>Speed things up by setting <a href=https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.device>device</a> to <code>cuda</code> if available else <code>cpu</code>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><p>Define a class of your model or use the predefined ResNet18 model (modified for MNIST) below, instantiate it and move it to device:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=k>class</span> <span class=nc>Net</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>Net</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        
        <span class=c1># Changed the output layer to output 10 classes instead of 1000 classes</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>resnet18</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>

        <span class=c1># Changed the input layer to take grayscale images for MNIST instaed of RGB images</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span> <span class=n>stride</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span> <span class=n>padding</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>


<span class=n>model</span> <span class=o>=</span> <span class=n>Net</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><p>Now let us define the training and validation datasets (as
<a href=https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader>torch.utils.data.DataLoader</a>)
and store them in <code>train_loader</code> and <code>val_loader</code> respectively. We have
used the <a href=https://pytorch.org/vision/stable/datasets.html#mnist>MNIST</a>
dataset for ease of understanding.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=n>data_transform</span> <span class=o>=</span> <span class=n>Compose</span><span class=p>([</span><span class=n>ToTensor</span><span class=p>(),</span> <span class=n>Normalize</span><span class=p>((</span><span class=mf>0.1307</span><span class=p>,),</span> <span class=p>(</span><span class=mf>0.3081</span><span class=p>,))])</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>MNIST</span><span class=p>(</span><span class=n>download</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>root</span><span class=o>=</span><span class=s2>&#34;.&#34;</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>data_transform</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=bp>True</span><span class=p>),</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=bp>True</span>
<span class=p>)</span>

<span class=n>val_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>MNIST</span><span class=p>(</span><span class=n>download</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>root</span><span class=o>=</span><span class=s2>&#34;.&#34;</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>data_transform</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=bp>False</span><span class=p>),</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=bp>False</span>
<span class=p>)</span>
</code></pre></td></tr></table></div></div><p>Finally, we will specify the optimizer and the loss function:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>RMSprop</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.005</span><span class=p>)</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</code></pre></td></tr></table></div></div><p>And we’re done with setting up the important parts of the project.
PyTorch-Ignite will handle all other boilerplate code as we will see
below. Next we have to define a trainer engine by passing our model,
optimizer and loss function to
<a href=https://pytorch.org/ignite/generated/ignite.engine.create_supervised_trainer.html><code>create_supervised_trainer</code></a>,
and two evaluator engines by passing Ignite’s out-of-the-box
<a href=https://pytorch.org/ignite/metrics.html#complete-list-of-metrics>metrics</a>
and the model to
<a href=https://pytorch.org/ignite/generated/ignite.engine.create_supervised_evaluator.html#create-supervised-evaluator><code>create_supervised_evaluator</code></a>. We have defined separate evaluator engines for training and validation because they will serve different functions as we will see later in this tutorial:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=n>trainer</span> <span class=o>=</span> <span class=n>create_supervised_trainer</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>criterion</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span>

<span class=n>val_metrics</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&#34;accuracy&#34;</span><span class=p>:</span> <span class=n>Accuracy</span><span class=p>(),</span>
    <span class=s2>&#34;loss&#34;</span><span class=p>:</span> <span class=n>Loss</span><span class=p>(</span><span class=n>criterion</span><span class=p>)</span>
<span class=p>}</span>

<span class=n>train_evaluator</span> <span class=o>=</span> <span class=n>create_supervised_evaluator</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=n>val_metrics</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
<span class=n>val_evaluator</span> <span class=o>=</span> <span class=n>create_supervised_evaluator</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=n>val_metrics</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><p>The objects <code>trainer</code>, <code>train_evaluator</code> and <code>val_evaluator</code> are all instances of
<a href=https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine><code>Engine</code></a> - the main component of Ignite, which is essentially an abstraction over
the training or validation loop.</p><p>If you need more control over your training and validation loops, you
can create custom <code>trainer</code>, <code>train_evaluator</code> and <code>val_evaluator</code> objects by wrapping the step
logic in <code>Engine</code> :</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>train_step</span><span class=p>(</span><span class=n>engine</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
    <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>batch</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>y_pred</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
    <span class=k>return</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>

<span class=n>trainer</span> <span class=o>=</span> <span class=n>Engine</span><span class=p>(</span><span class=n>train_step</span><span class=p>)</span>

<span class=k>def</span> <span class=nf>validation_step</span><span class=p>(</span><span class=n>engine</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>batch</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
        <span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>y</span>

<span class=n>train_evaluator</span> <span class=o>=</span> <span class=n>Engine</span><span class=p>(</span><span class=n>validation_step</span><span class=p>)</span>
<span class=n>val_evaluator</span> <span class=o>=</span> <span class=n>Engine</span><span class=p>(</span><span class=n>validation_step</span><span class=p>)</span>

<span class=c1># Attach metrics to the evaluators</span>
<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>metric</span> <span class=ow>in</span> <span class=n>val_metrics</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=n>metric</span><span class=o>.</span><span class=n>attach</span><span class=p>(</span><span class=n>train_evaluator</span><span class=p>,</span> <span class=n>name</span><span class=p>)</span>

<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>metric</span> <span class=ow>in</span> <span class=n>val_metrics</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=n>metric</span><span class=o>.</span><span class=n>attach</span><span class=p>(</span><span class=n>val_evaluator</span><span class=p>,</span> <span class=n>name</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><p>We can customize the code further by adding all kinds of event handlers.
<code>Engine</code> allows adding handlers on various events that are triggered
during the run. When an event is triggered, attached handlers
(functions) are executed. Thus, for logging purposes we add a function
to be executed at the end of every <code>log_interval</code>-th iteration:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># How many batches to wait before logging training status</span>
<span class=n>log_interval</span> <span class=o>=</span> <span class=mi>100</span>
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=nd>@trainer.on</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>ITERATION_COMPLETED</span><span class=p>(</span><span class=n>every</span><span class=o>=</span><span class=n>log_interval</span><span class=p>))</span>
<span class=k>def</span> <span class=nf>log_training_loss</span><span class=p>(</span><span class=n>engine</span><span class=p>):</span>
    <span class=k>print</span><span class=p>(</span><span class=n>f</span><span class=s2>&#34;Epoch[{engine.state.epoch}], Iter[{engine.state.iteration}] Loss: {engine.state.output:.2f}&#34;</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><p>or equivalently without the decorator but attaching the handler function
to the <code>trainer</code> via
<a href=https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine.add_event_handler><code>add_event_handler</code></a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>log_training_loss</span><span class=p>(</span><span class=n>engine</span><span class=p>):</span>
    <span class=k>print</span><span class=p>(</span><span class=n>f</span><span class=s2>&#34;Epoch[{engine.state.epoch}], Iter[{engine.state.iteration}] Loss: {engine.state.output:.2f}&#34;</span><span class=p>)</span>

<span class=n>trainer</span><span class=o>.</span><span class=n>add_event_handler</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>ITERATION_COMPLETED</span><span class=p>,</span> <span class=n>log_training_loss</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><p>After an epoch ends during training, we can compute the training and
validation metrics by running <code>evaluator</code> on <code>train_loader</code> and
<code>val_loader</code>. Hence we will attach two additional handlers to <code>trainer</code>
when an epoch completes:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=nd>@trainer.on</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>EPOCH_COMPLETED</span><span class=p>)</span>
<span class=k>def</span> <span class=nf>log_training_results</span><span class=p>(</span><span class=n>trainer</span><span class=p>):</span>
    <span class=n>train_evaluator</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>train_loader</span><span class=p>)</span>
    <span class=n>metrics</span> <span class=o>=</span> <span class=n>train_evaluator</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>metrics</span>
    <span class=k>print</span><span class=p>(</span><span class=n>f</span><span class=s2>&#34;Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics[&#39;accuracy&#39;]:.2f} Avg loss: {metrics[&#39;loss&#39;]:.2f}&#34;</span><span class=p>)</span>


<span class=nd>@trainer.on</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>EPOCH_COMPLETED</span><span class=p>)</span>
<span class=k>def</span> <span class=nf>log_validation_results</span><span class=p>(</span><span class=n>trainer</span><span class=p>):</span>
    <span class=n>val_evaluator</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>val_loader</span><span class=p>)</span>
    <span class=n>metrics</span> <span class=o>=</span> <span class=n>val_evaluator</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>metrics</span>
    <span class=k>print</span><span class=p>(</span><span class=n>f</span><span class=s2>&#34;Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics[&#39;accuracy&#39;]:.2f} Avg loss: {metrics[&#39;loss&#39;]:.2f}&#34;</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><p>We can use <a href=https://pytorch.org/ignite/generated/ignite.handlers.checkpoint.ModelCheckpoint.html#modelcheckpoint><code>ModelCheckpoint()</code></a> as shown below to save the <code>n_saved</code> best models determined by a metric (here accuracy) after each epoch is completed. We attach <code>model_checkpoint</code> to <code>val_evaluator</code> because we want the two models with the highest accuracies on the validation dataset rather than the training dataset. This is why we defined two separate evaluators (<code>val_evaluator</code> and <code>train_evaluator</code>) before.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># Score function to return current value of any metric we defined above in val_metrics</span>
<span class=k>def</span> <span class=nf>score_function</span><span class=p>(</span><span class=n>engine</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>engine</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;accuracy&#34;</span><span class=p>]</span>

<span class=c1># Checkpoint to store n_saved best models wrt score function</span>
<span class=n>model_checkpoint</span> <span class=o>=</span> <span class=n>ModelCheckpoint</span><span class=p>(</span>
    <span class=s2>&#34;checkpoint&#34;</span><span class=p>,</span>
    <span class=n>n_saved</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
    <span class=n>filename_prefix</span><span class=o>=</span><span class=s2>&#34;best&#34;</span><span class=p>,</span>
    <span class=n>score_function</span><span class=o>=</span><span class=n>score_function</span><span class=p>,</span>
    <span class=n>score_name</span><span class=o>=</span><span class=s2>&#34;accuracy&#34;</span><span class=p>,</span>
    <span class=n>global_step_transform</span><span class=o>=</span><span class=n>global_step_from_engine</span><span class=p>(</span><span class=n>trainer</span><span class=p>),</span> <span class=c1># helps fetch the trainer&#39;s state</span>
<span class=p>)</span>
  
<span class=c1># Save the model after every epoch of val_evaluator is completed</span>
<span class=n>val_evaluator</span><span class=o>.</span><span class=n>add_event_handler</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>COMPLETED</span><span class=p>,</span> <span class=n>model_checkpoint</span><span class=p>,</span> <span class=p>{</span><span class=s2>&#34;model&#34;</span><span class=p>:</span> <span class=n>model</span><span class=p>})</span>
</code></pre></td></tr></table></div></div><p>We will use <a href=https://pytorch.org/ignite/generated/ignite.contrib.handlers.tensorboard_logger.html#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger><code>TensorboardLogger()</code></a> to log trainer&rsquo;s loss, and training and validation metrics separately.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># Define a Tensorboard logger</span>
<span class=n>tb_logger</span> <span class=o>=</span> <span class=n>TensorboardLogger</span><span class=p>(</span><span class=n>log_dir</span><span class=o>=</span><span class=s2>&#34;tb-logger&#34;</span><span class=p>)</span>

<span class=c1># Attach handler to plot trainer&#39;s loss every 100 iterations</span>
<span class=n>tb_logger</span><span class=o>.</span><span class=n>attach_output_handler</span><span class=p>(</span>
    <span class=n>trainer</span><span class=p>,</span>
    <span class=n>event_name</span><span class=o>=</span><span class=n>Events</span><span class=o>.</span><span class=n>ITERATION_COMPLETED</span><span class=p>(</span><span class=n>every</span><span class=o>=</span><span class=mi>100</span><span class=p>),</span>
    <span class=n>tag</span><span class=o>=</span><span class=s2>&#34;training&#34;</span><span class=p>,</span>
    <span class=n>output_transform</span><span class=o>=</span><span class=k>lambda</span> <span class=n>loss</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;batch_loss&#34;</span><span class=p>:</span> <span class=n>loss</span><span class=p>},</span>
<span class=p>)</span>

<span class=c1># Attach handler for plotting both evaluators&#39; metrics after every epoch completes</span>
<span class=k>for</span> <span class=n>tag</span><span class=p>,</span> <span class=n>evaluator</span> <span class=ow>in</span> <span class=p>[(</span><span class=s2>&#34;training&#34;</span><span class=p>,</span> <span class=n>train_evaluator</span><span class=p>),</span> <span class=p>(</span><span class=s2>&#34;validation&#34;</span><span class=p>,</span> <span class=n>val_evaluator</span><span class=p>)]:</span>
    <span class=n>tb_logger</span><span class=o>.</span><span class=n>attach_output_handler</span><span class=p>(</span>
        <span class=n>evaluator</span><span class=p>,</span>
        <span class=n>event_name</span><span class=o>=</span><span class=n>Events</span><span class=o>.</span><span class=n>EPOCH_COMPLETED</span><span class=p>,</span>
        <span class=n>tag</span><span class=o>=</span><span class=n>tag</span><span class=p>,</span>
        <span class=n>metric_names</span><span class=o>=</span><span class=s2>&#34;all&#34;</span><span class=p>,</span>
        <span class=n>global_step_transform</span><span class=o>=</span><span class=n>global_step_from_engine</span><span class=p>(</span><span class=n>trainer</span><span class=p>),</span>
    <span class=p>)</span>
</code></pre></td></tr></table></div></div><p>Finally, we start the engine on the training dataset and run it for 5
epochs:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=n>trainer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>train_loader</span><span class=p>,</span> <span class=n>max_epochs</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><pre><code>Epoch[1], Iter[100] Loss: 0.19
Epoch[1], Iter[200] Loss: 0.13
Epoch[1], Iter[300] Loss: 0.08
Epoch[1], Iter[400] Loss: 0.11
Training Results - Epoch[1] Avg accuracy: 0.97 Avg loss: 0.09
Validation Results - Epoch[1] Avg accuracy: 0.97 Avg loss: 0.08
Epoch[2], Iter[500] Loss: 0.07
Epoch[2], Iter[600] Loss: 0.04
Epoch[2], Iter[700] Loss: 0.09
Epoch[2], Iter[800] Loss: 0.07
Epoch[2], Iter[900] Loss: 0.16
Training Results - Epoch[2] Avg accuracy: 0.93 Avg loss: 0.20
Validation Results - Epoch[2] Avg accuracy: 0.93 Avg loss: 0.20
Epoch[3], Iter[1000] Loss: 0.02
Epoch[3], Iter[1100] Loss: 0.02
Epoch[3], Iter[1200] Loss: 0.05
Epoch[3], Iter[1300] Loss: 0.06
Epoch[3], Iter[1400] Loss: 0.06
Training Results - Epoch[3] Avg accuracy: 0.94 Avg loss: 0.20
Validation Results - Epoch[3] Avg accuracy: 0.94 Avg loss: 0.23
Epoch[4], Iter[1500] Loss: 0.08
Epoch[4], Iter[1600] Loss: 0.02
Epoch[4], Iter[1700] Loss: 0.08
Epoch[4], Iter[1800] Loss: 0.07
Training Results - Epoch[4] Avg accuracy: 0.98 Avg loss: 0.06
Validation Results - Epoch[4] Avg accuracy: 0.98 Avg loss: 0.07
Epoch[5], Iter[1900] Loss: 0.02
Epoch[5], Iter[2000] Loss: 0.11
Epoch[5], Iter[2100] Loss: 0.05
Epoch[5], Iter[2200] Loss: 0.02
Epoch[5], Iter[2300] Loss: 0.01
Training Results - Epoch[5] Avg accuracy: 0.99 Avg loss: 0.02
Validation Results - Epoch[5] Avg accuracy: 0.99 Avg loss: 0.03





State:
	iteration: 2345
	epoch: 5
	epoch_length: 469
	max_epochs: 5
	output: 0.005351857747882605
	batch: &lt;class 'list'&gt;
	metrics: &lt;class 'dict'&gt;
	dataloader: &lt;class 'torch.utils.data.dataloader.DataLoader'&gt;
	seed: &lt;class 'NoneType'&gt;
	times: &lt;class 'dict'&gt;
</code></pre><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># Let&#39;s close the logger and inspect our results</span>
<span class=n>tb_logger</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>

<span class=o>%</span><span class=n>load_ext</span> <span class=n>tensorboard</span>

<span class=o>%</span><span class=n>tensorboard</span> <span class=o>--</span><span class=n>logdir</span><span class=o>=.</span>
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># At last we can view our best models</span>
<span class=err>!</span><span class=n>ls</span> <span class=n>checkpoints</span>
</code></pre></td></tr></table></div></div><pre><code>'best_model_4_accuracy=0.9856.pt'  'best_model_5_accuracy=0.9857.pt'
</code></pre><h2 id=next-steps>Next Steps</h2><ol><li>Check out <a href=https://pytorch-ignite.ai/docs/tutorials>tutorials</a> if you want to continue
learning more about PyTorch-Ignite.</li><li>Head over to <a href=https://pytorch-ignite.ai/docs/how-to-guides>how-to guides</a> if you’re looking
for a specific solution.</li><li>If you want to set-up a PyTorch-Ignite project, visit <a href=https://code-generator.pytorch-ignite.ai/>Code
Generator</a> to get a variety of
easily customizable templates and out-of-the-box features.</li></ol><h2 id=complete-code>Complete Code</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>from</span> <span class=nn>torch</span> <span class=kn>import</span> <span class=n>nn</span>
<span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span>
<span class=kn>from</span> <span class=nn>torchvision.datasets</span> <span class=kn>import</span> <span class=n>MNIST</span>
<span class=kn>from</span> <span class=nn>torchvision.models</span> <span class=kn>import</span> <span class=n>resnet18</span>
<span class=kn>from</span> <span class=nn>torchvision.transforms</span> <span class=kn>import</span> <span class=n>Compose</span><span class=p>,</span> <span class=n>Normalize</span><span class=p>,</span> <span class=n>ToTensor</span>

<span class=kn>from</span> <span class=nn>ignite.engine</span> <span class=kn>import</span> <span class=n>Engine</span><span class=p>,</span> <span class=n>Events</span><span class=p>,</span> <span class=n>create_supervised_trainer</span><span class=p>,</span> <span class=n>create_supervised_evaluator</span>
<span class=kn>from</span> <span class=nn>ignite.metrics</span> <span class=kn>import</span> <span class=n>Accuracy</span><span class=p>,</span> <span class=n>Loss</span>
<span class=kn>from</span> <span class=nn>ignite.contrib.handlers</span> <span class=kn>import</span> <span class=n>TensorboardLogger</span><span class=p>,</span> <span class=n>global_step_from_engine</span>

<span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>


<span class=k>class</span> <span class=nc>Net</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>Net</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
    
        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>resnet18</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span> <span class=n>stride</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span> <span class=n>padding</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>


<span class=n>model</span> <span class=o>=</span> <span class=n>Net</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

<span class=n>data_transform</span> <span class=o>=</span> <span class=n>Compose</span><span class=p>([</span><span class=n>ToTensor</span><span class=p>(),</span> <span class=n>Normalize</span><span class=p>((</span><span class=mf>0.1307</span><span class=p>,),</span> <span class=p>(</span><span class=mf>0.3081</span><span class=p>,))])</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>MNIST</span><span class=p>(</span><span class=n>download</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>root</span><span class=o>=</span><span class=s2>&#34;.&#34;</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>data_transform</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=bp>True</span><span class=p>),</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=bp>True</span>
<span class=p>)</span>

<span class=n>val_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>MNIST</span><span class=p>(</span><span class=n>download</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>root</span><span class=o>=</span><span class=s2>&#34;.&#34;</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>data_transform</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=bp>False</span><span class=p>),</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=bp>False</span>
<span class=p>)</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>RMSprop</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.005</span><span class=p>)</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>

<span class=n>trainer</span> <span class=o>=</span> <span class=n>create_supervised_trainer</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>criterion</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span>

<span class=n>val_metrics</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&#34;accuracy&#34;</span><span class=p>:</span> <span class=n>Accuracy</span><span class=p>(),</span>
    <span class=s2>&#34;loss&#34;</span><span class=p>:</span> <span class=n>Loss</span><span class=p>(</span><span class=n>criterion</span><span class=p>)</span>
<span class=p>}</span>

<span class=n>train_evaluator</span> <span class=o>=</span> <span class=n>create_supervised_evaluator</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=n>val_metrics</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
<span class=n>val_evaluator</span> <span class=o>=</span> <span class=n>create_supervised_evaluator</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=n>val_metrics</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>

<span class=n>log_interval</span> <span class=o>=</span> <span class=mi>100</span>

<span class=nd>@trainer.on</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>ITERATION_COMPLETED</span><span class=p>(</span><span class=n>every</span><span class=o>=</span><span class=n>log_interval</span><span class=p>))</span>
<span class=k>def</span> <span class=nf>log_training_loss</span><span class=p>(</span><span class=n>engine</span><span class=p>):</span>
    <span class=k>print</span><span class=p>(</span><span class=n>f</span><span class=s2>&#34;Epoch[{engine.state.epoch}], Iter[{engine.state.iteration}] Loss: {engine.state.output:.2f}&#34;</span><span class=p>)</span>

<span class=nd>@trainer.on</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>EPOCH_COMPLETED</span><span class=p>)</span>
<span class=k>def</span> <span class=nf>log_training_results</span><span class=p>(</span><span class=n>trainer</span><span class=p>):</span>
    <span class=n>train_evaluator</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>train_loader</span><span class=p>)</span>
    <span class=n>metrics</span> <span class=o>=</span> <span class=n>train_evaluator</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>metrics</span>
    <span class=k>print</span><span class=p>(</span><span class=n>f</span><span class=s2>&#34;Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics[&#39;accuracy&#39;]:.2f} Avg loss: {metrics[&#39;loss&#39;]:.2f}&#34;</span><span class=p>)</span>


<span class=nd>@trainer.on</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>EPOCH_COMPLETED</span><span class=p>)</span>
<span class=k>def</span> <span class=nf>log_validation_results</span><span class=p>(</span><span class=n>trainer</span><span class=p>):</span>
    <span class=n>val_evaluator</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>val_loader</span><span class=p>)</span>
    <span class=n>metrics</span> <span class=o>=</span> <span class=n>val_evaluator</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>metrics</span>
    <span class=k>print</span><span class=p>(</span><span class=n>f</span><span class=s2>&#34;Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics[&#39;accuracy&#39;]:.2f} Avg loss: {metrics[&#39;loss&#39;]:.2f}&#34;</span><span class=p>)</span>


<span class=k>def</span> <span class=nf>score_function</span><span class=p>(</span><span class=n>engine</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>engine</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;accuracy&#34;</span><span class=p>]</span>


<span class=n>model_checkpoint</span> <span class=o>=</span> <span class=n>ModelCheckpoint</span><span class=p>(</span>
    <span class=s2>&#34;checkpoint&#34;</span><span class=p>,</span>
    <span class=n>n_saved</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
    <span class=n>filename_prefix</span><span class=o>=</span><span class=s2>&#34;best&#34;</span><span class=p>,</span>
    <span class=n>score_function</span><span class=o>=</span><span class=n>score_function</span><span class=p>,</span>
    <span class=n>score_name</span><span class=o>=</span><span class=s2>&#34;accuracy&#34;</span><span class=p>,</span>
    <span class=n>global_step_transform</span><span class=o>=</span><span class=n>global_step_from_engine</span><span class=p>(</span><span class=n>trainer</span><span class=p>),</span>
<span class=p>)</span>
  
<span class=n>val_evaluator</span><span class=o>.</span><span class=n>add_event_handler</span><span class=p>(</span><span class=n>Events</span><span class=o>.</span><span class=n>COMPLETED</span><span class=p>,</span> <span class=n>model_checkpoint</span><span class=p>,</span> <span class=p>{</span><span class=s2>&#34;model&#34;</span><span class=p>:</span> <span class=n>model</span><span class=p>})</span>

<span class=n>tb_logger</span> <span class=o>=</span> <span class=n>TensorboardLogger</span><span class=p>(</span><span class=n>log_dir</span><span class=o>=</span><span class=s2>&#34;tb-logger&#34;</span><span class=p>)</span>

<span class=n>tb_logger</span><span class=o>.</span><span class=n>attach_output_handler</span><span class=p>(</span>
    <span class=n>trainer</span><span class=p>,</span>
    <span class=n>event_name</span><span class=o>=</span><span class=n>Events</span><span class=o>.</span><span class=n>ITERATION_COMPLETED</span><span class=p>(</span><span class=n>every</span><span class=o>=</span><span class=mi>100</span><span class=p>),</span>
    <span class=n>tag</span><span class=o>=</span><span class=s2>&#34;training&#34;</span><span class=p>,</span>
    <span class=n>output_transform</span><span class=o>=</span><span class=k>lambda</span> <span class=n>loss</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;batch_loss&#34;</span><span class=p>:</span> <span class=n>loss</span><span class=p>},</span>
<span class=p>)</span>

<span class=k>for</span> <span class=n>tag</span><span class=p>,</span> <span class=n>evaluator</span> <span class=ow>in</span> <span class=p>[(</span><span class=s2>&#34;training&#34;</span><span class=p>,</span> <span class=n>train_evaluator</span><span class=p>),</span> <span class=p>(</span><span class=s2>&#34;validation&#34;</span><span class=p>,</span> <span class=n>val_evaluator</span><span class=p>)]:</span>
    <span class=n>tb_logger</span><span class=o>.</span><span class=n>attach_output_handler</span><span class=p>(</span>
        <span class=n>evaluator</span><span class=p>,</span>
        <span class=n>event_name</span><span class=o>=</span><span class=n>Events</span><span class=o>.</span><span class=n>EPOCH_COMPLETED</span><span class=p>,</span>
        <span class=n>tag</span><span class=o>=</span><span class=n>tag</span><span class=p>,</span>
        <span class=n>metric_names</span><span class=o>=</span><span class=s2>&#34;all&#34;</span><span class=p>,</span>
        <span class=n>global_step_transform</span><span class=o>=</span><span class=n>global_step_from_engine</span><span class=p>(</span><span class=n>trainer</span><span class=p>),</span>
    <span class=p>)</span>

<span class=n>trainer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>train_loader</span><span class=p>,</span> <span class=n>max_epochs</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>

<span class=n>tb_logger</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</code></pre></td></tr></table></div></div></div><div class=prev-n-next><div class=prev></div></div></div></section><div id=backtotop><a href=#></a></div><div class=sidebar><div class=sidebar-header><a class=sidebar-close href=javascript:void(0);><i data-feather=x></i></a><div class=text>Tutorials</div></div><div class=inner><aside><ul><li><a href=/tutorials/getting-started/ class=active>Getting Started</a><nav id=TableOfContents><ul><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#installation>Installation</a></li><li><a href=#code>Code</a></li><li><a href=#next-steps>Next Steps</a></li><li><a href=#complete-code>Complete Code</a></li></ul></nav></li></ul></aside></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@2.2.4/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/feather-icons@4.28.0/dist/feather.min.js></script><script src=/js/modernizr.min.48806575a40ede5e406c8278f3be521afb171e73d324994ced6b41306bdb230a.js></script><script src=/js/fresh.js></script><script src=/js/jquery.panelslider.min.js></script><link rel=stylesheet href=/css/syntax.min.84ca75a88a5562d09268f7057015aed4c2092f04a31d084196a754689084b803.css><link rel=stylesheet href=/css/copy-code.min.878089dd803b72dd5f7d0b3fbf80963bb8e0cae8cea4404fce33ac8386c593ca.css><script src=/js/copy-code.min.202e074c00305627d6c50240703860f57f00aef8cdea3d0b66809dbdeba70e95.js></script></body></html>